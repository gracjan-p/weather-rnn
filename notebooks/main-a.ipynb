{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "In this small project we will take a look at Seattle weather dataset from Kaggle to extract important features and use them to test functionality of Recurrent Neural Network.\n",
    "<br><br>\n",
    "#### Main objective\n",
    "Build a model using PyTorch library that predicts temperature for the next day.\n",
    "<br><br>\n",
    "#### Process includes:\n",
    "1. **Data** <br>\n",
    "&ensp;1.1 Overview <br>\n",
    "&ensp;1.2 Anomalies <br>\n",
    "&ensp;1.3 Visualization <br>\n",
    "&ensp;1.4 Preparing data for model <br>\n",
    "2. **Building model** <br>\n",
    "&ensp;2.1 Train / test split <br>\n",
    "&ensp;2.2 Sequencing datasets <br>\n",
    "&ensp;2.3 Class LSTM <br>\n",
    "&ensp;2.4 Training function <br>\n",
    "&ensp;2.5 Testing function <br>\n",
    "&ensp;2.6 Training and Testing the RNN models <br>\n",
    "3. **Conclusion**"
   ],
   "id": "9f988730a9f468c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Setup",
   "id": "6a93d4a9fcb6a55e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T00:51:25.421908Z",
     "start_time": "2025-04-27T00:51:24.289589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "WHITE_MID = '#b5b5b5'\n",
    "GREY_DARK = '#141414'\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = GREY_DARK\n",
    "plt.rcParams['text.color'] = WHITE_MID\n",
    "plt.rcParams['axes.facecolor'] = GREY_DARK\n",
    "plt.rcParams['axes.edgecolor'] = WHITE_MID\n",
    "plt.rcParams['axes.labelcolor'] = WHITE_MID\n",
    "plt.rcParams['axes.titlecolor'] = WHITE_MID\n",
    "\n",
    "plt.rcParams['grid.color'] = WHITE_MID\n",
    "plt.rcParams['grid.linestyle'] = '--'\n",
    "plt.rcParams['grid.linewidth'] = 0.5\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "plt.rcParams['xtick.color'] = WHITE_MID\n",
    "plt.rcParams['ytick.color'] = WHITE_MID\n",
    "plt.rcParams['legend.edgecolor'] = WHITE_MID\n",
    "plt.rcParams['legend.labelcolor'] = WHITE_MID"
   ],
   "id": "f591f0f57656af6c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T00:51:29.209755Z",
     "start_time": "2025-04-27T00:51:26.259990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "e33e1d9469ad1c0a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# I - Load Data",
   "id": "f6676f7817f4eef5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T00:51:41.062334Z",
     "start_time": "2025-04-27T00:51:40.148475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../datasets/weather-processed.csv')\n",
    "df"
   ],
   "id": "e8c4d9b7e5bfddd5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      precipitation      wind  temp_avg\n",
       "0          0.000000  0.472527  0.416393\n",
       "1          0.194991  0.450549  0.344262\n",
       "2          0.014311  0.208791  0.434426\n",
       "3          0.363148  0.472527  0.416393\n",
       "4          0.023256  0.626374  0.316393\n",
       "...             ...       ...       ...\n",
       "1456       0.153846  0.274725  0.224590\n",
       "1457       0.026834  0.098901  0.234426\n",
       "1458       0.000000  0.241758  0.252459\n",
       "1459       0.000000  0.329670  0.200000\n",
       "1460       0.000000  0.340659  0.181967\n",
       "\n",
       "[1461 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precipitation</th>\n",
       "      <th>wind</th>\n",
       "      <th>temp_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.416393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.194991</td>\n",
       "      <td>0.450549</td>\n",
       "      <td>0.344262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014311</td>\n",
       "      <td>0.208791</td>\n",
       "      <td>0.434426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.363148</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.416393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.316393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.274725</td>\n",
       "      <td>0.224590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.026834</td>\n",
       "      <td>0.098901</td>\n",
       "      <td>0.234426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241758</td>\n",
       "      <td>0.252459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329670</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.181967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1461 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# II - Building model\n",
    "#### 2.1 Train / test split\n",
    "Splitting dataset using week stamps."
   ],
   "id": "d9e285270e10d81d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T00:51:47.865445Z",
     "start_time": "2025-04-27T00:51:47.859862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_size = int(len(df) * 0.7) + 1\n",
    "test_size = int(len(df) * 0.3)\n",
    "\n",
    "print(\n",
    "    f\"{f\"train size\":>12}: {train_size}\",\n",
    "    f\"{f\"test size\":>12}: {test_size}\",\n",
    "    len(df) == train_size + test_size,\n",
    "    sep='\\n'\n",
    ")"
   ],
   "id": "9b2debeeda67b756",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train size: 1023\n",
      "   test size: 438\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T00:51:48.642673Z",
     "start_time": "2025-04-27T00:51:48.638174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = df[:train_size]\n",
    "df_test = df[train_size:]"
   ],
   "id": "7f687d508b204799",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We're going to pass sequenced data with length of 7 days per sequence. <br>\n",
    "Knowing that, we have to make sure that our datasets are divisible by 7. <br>"
   ],
   "id": "fd64df1f598cc281"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T00:51:50.893303Z",
     "start_time": "2025-04-27T00:51:50.888312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = df_train[:(len(df_train) // 7) * 7]\n",
    "df_test = df_test[:(len(df_test) // 7) * 7]"
   ],
   "id": "939b33504795111e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T00:51:51.620254Z",
     "start_time": "2025-04-27T00:51:51.615713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\n",
    "    len(df_train),\n",
    "    len(df_test), sep='\\n'\n",
    ")"
   ],
   "id": "592dd950e6fb063d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022\n",
      "434\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Convert each data split to numpy, so we're able to pass it to torch.",
   "id": "14c9b4a8b7765d10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T00:51:54.475479Z",
     "start_time": "2025-04-27T00:51:54.463795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train_torch = df_train.to_numpy()\n",
    "df_train_torch = torch.tensor(df_train_torch)\n",
    "\n",
    "df_test_torch = df_test.to_numpy()\n",
    "df_test_torch = torch.tensor(df_test_torch)\n",
    "df_test_torch[:7]"
   ],
   "id": "f6de761f5c5ade6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2093, 0.2967, 0.5885],\n",
       "        [0.0179, 0.4725, 0.5803],\n",
       "        [0.5725, 0.5055, 0.5721],\n",
       "        [0.1682, 0.4615, 0.4967],\n",
       "        [0.0733, 0.3077, 0.5066],\n",
       "        [0.1091, 0.5495, 0.5344],\n",
       "        [0.0268, 0.5055, 0.4623]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.2 - Sequencing datasets\n",
    "To predict temperature based on features from past 6 days, <br>\n",
    "we have to reshape our data split sets to return specific sequences. <br><br>\n",
    "Each sequence containing data from 7 days, where: <br>\n",
    "X - temp_avg features from first 6 days <br>\n",
    "y - same features, but we take just day 7th"
   ],
   "id": "e90715a5b5a46716"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T01:04:20.994172Z",
     "start_time": "2025-04-27T01:04:20.986476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def sequence_dataset(dataset, batch_size, extra_features=False):\n",
    "    \n",
    "    x, y = [], []\n",
    "    \n",
    "    for i in range(0, len(dataset) - 7, 7):\n",
    "        \n",
    "        if extra_features:\n",
    "            week = dataset[i: i + 7, :] # take just the temperature (2)\n",
    "        else:\n",
    "            week = dataset[i: i + 7, 2] # take just the temperature (2)\n",
    "        week_features = week[:6] # trim to 6 days\n",
    "        week_target = week[6] # take last day\n",
    "        \n",
    "        x.append(week_features)\n",
    "        y.append(week_target)\n",
    "        \n",
    "    # covert to tensor dataset\n",
    "    tensor_dataset = TensorDataset(torch.tensor(np.asarray(x)),\n",
    "                                   torch.tensor(np.asarray(y)))\n",
    "    \n",
    "    # covert to data_loader\n",
    "    data_loader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    return data_loader"
   ],
   "id": "f55402288d2398b",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T01:04:21.251461Z",
     "start_time": "2025-04-27T01:04:21.231055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 8\n",
    "train_loader = sequence_dataset(df_train_torch, batch_size=batch_size)\n",
    "test_loader = sequence_dataset(df_test_torch, batch_size=batch_size)"
   ],
   "id": "5d1936ec49fb6c44",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T01:04:32.962389Z",
     "start_time": "2025-04-27T01:04:32.956971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in train_loader:\n",
    "    input, target = batch\n",
    "    # print(input, target)\n",
    "    print(input.size())\n",
    "    print(target.size())\n",
    "    # print(len(target))\n",
    "    break"
   ],
   "id": "772b0da72f919eee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T01:05:07.640846Z",
     "start_time": "2025-04-27T01:05:07.630026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in train_loader:\n",
    "    input, target = batch\n",
    "    print(input[0], target[0], sep='\\n')\n",
    "    break"
   ],
   "id": "d2c519b521e703a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0885, 0.1426, 0.2246, 0.1607, 0.1426, 0.1607], dtype=torch.float64)\n",
      "tensor(0.1328, dtype=torch.float64)\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.3 class LSTM\n",
    "With PyTorch we are able to build simple RNN with Long Short-Term Memory layers by simply attaching _nn.LSTM()_ with specific factors in it. <br>\n",
    "The __init__ function first initializes the LSTM and fully connected layers. <br>\n",
    "__*forward()*__ passes our input x to the rnn network then fully connects it to finally return last value from the output."
   ],
   "id": "9736826d8b8f86f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "class WeatherRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=3, n_layers=2, dropout=0):\n",
    "        super(WeatherRNN, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :]) # take the last hidden\n",
    "        return out"
   ],
   "id": "a6d6ea3cef0ac0da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.4 Training function\n",
    "So we take our train_loader and pass it to our training function. <br>\n",
    "Training function iterates over batches for n_epoch times and passes sequences from these batches to our model <br>\n",
    "that calculates loss by comparing calculated outputs with actual targets using Mean Squared Error function."
   ],
   "id": "64ddf19a565f0f9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, device, train_loader, n_epochs=1, lr=0.001):\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = (inputs.to(device).float(),\n",
    "                               targets.to(device).float())\n",
    "\n",
    "            inputs = inputs.unsqueeze(-1)\n",
    "            \n",
    "            optimizer.zero_grad() # clean gradients\n",
    "            outputs = model(inputs) # calculate outputs\n",
    "            \n",
    "            loss = criterion(outputs, targets.unsqueeze(1)) # add dim\n",
    "            loss.backward() # backpropagation\n",
    "            optimizer.step() # update weights\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1} / {n_epochs} finished | {total_loss/len(train_loader):.4f}\")"
   ],
   "id": "c149884f8a3e3ac7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.5 Testing function\n",
    "Similar to training function. This time we run the model with no gradients calculations <br>\n",
    "and iterate through batches from test_loader. <br>\n",
    "Then return y true and y predicted values to compare where the model makes most mistakes."
   ],
   "id": "f2c8ce9e9d98917d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def test_model(model, device, test_loader):\n",
    "    total_loss = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = (inputs.to(device).float(),\n",
    "                               targets.to(device).float())\n",
    "            \n",
    "            inputs = inputs.unsqueeze(-1)\n",
    "\n",
    "            outputs = model(inputs) # get outputs\n",
    "\n",
    "            loss = criterion(outputs, targets.unsqueeze(1)) # add dim\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            y_true.extend(targets.cpu().numpy())\n",
    "            y_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    print(f\"Test MSE Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return y_true, y_pred\n"
   ],
   "id": "e03eaec27e834ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.6 Training and Testing the RNN models",
   "id": "7981d93c47fcbaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "hidden_size = 128\n",
    "n_layers = 1\n",
    "dropout = 0\n",
    "learning_rate = 0.0005\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "weather_rnn = WeatherRNN(input_size=input_size, hidden_size=hidden_size, n_layers=n_layers, output_size=output_size, dropout=dropout)"
   ],
   "id": "4b78278af1d420aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_model(weather_rnn, device=device, train_loader=train_loader, n_epochs=n_epochs, lr=learning_rate)",
   "id": "408c9346150f64ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_true, y_pred = test_model(weather_rnn, device=device, test_loader=test_loader)",
   "id": "458a0553885943",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "temp_avg_true = np.array(y_true).flatten()\n",
    "temp_avg_pred = np.array(y_pred).flatten()"
   ],
   "id": "ca7eb7f23fa48f33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(24, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "x = range(len(temp_avg_true))\n",
    "axes[0].vlines(x=x, ymin=temp_avg_pred, ymax=temp_avg_true, color='red', linewidth=1, label='error')\n",
    "axes[0].plot(x, y_pred, marker='+', linestyle='None', color='white', label='pred')\n",
    "\n",
    "sb.lineplot(x=range(len(temp_avg_true)), y=temp_avg_true, color='red', ax=axes[1], label='true')\n",
    "sb.lineplot(x=range(len(temp_avg_pred)), y=temp_avg_pred, color='white', ax=axes[1], label='pred')\n",
    "\n",
    "axes[0].set_title('Predictions Errors')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_title('True and Predicted overlap')\n",
    "\n",
    "plt.suptitle('Predictions Summary', fontweight='bold')\n",
    "plt.tight_layout()"
   ],
   "id": "d7a4bcf54377ae33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import hmean\n",
    "\n",
    "true_deg = np.zeros((len(temp_avg_true), input_size))\n",
    "pred_deg = np.zeros((len(temp_avg_pred), input_size))\n",
    "\n",
    "true_deg = np.sqrt(temp_avg_true).reshape(-1, 1)\n",
    "pred_deg = np.sqrt(temp_avg_pred).reshape(-1, 1)\n",
    "\n",
    "true_deg = scaler.inverse_transform(true_deg)\n",
    "pred_deg = scaler.inverse_transform(pred_deg)\n",
    "\n",
    "diff = abs(true_deg - pred_deg)\n",
    "\n",
    "print(\n",
    "    f\"{\"mean\":>6}: {diff.mean()}\",\n",
    "    f\"{\"hmean\":>6}: {hmean(diff)}\",\n",
    "    f\"{\"max\":>6}: {diff.max()}\",\n",
    "    f\"{\"min\":>6}: {diff.min()}\",\n",
    "    f\"{\"min\":>6}: {true_deg.max() - true_deg.min()}\",\n",
    "    sep='\\n'\n",
    ")"
   ],
   "id": "1fca7bd6eedfb6e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "diff",
   "id": "3e69ce6e7cd9c675",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "precip_true = np.array(y_true)[:, 0]\n",
    "precip_pred = np.array(y_pred)[:, 0]\n",
    "\n",
    "temp_avg_true = np.array(y_true)[:, 1]\n",
    "temp_avg_pred = np.array(y_pred)[:, 1]\n",
    "\n",
    "wind_true = np.array(y_true)[:, 2]\n",
    "wind_pred = np.array(y_pred)[:, 2]"
   ],
   "id": "28f68446dac39720",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(24, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "sb.lineplot(x=range(len(precip_true)), y=precip_true, color='red', ax=axes[0], label='True')\n",
    "sb.lineplot(x=range(len(precip_pred)), y=precip_pred, color='white', ax=axes[0], label='Pred')\n",
    "axes[0].set_title('precipitation')\n",
    "\n",
    "sb.lineplot(x=range(len(temp_avg_true)), y=temp_avg_true, color='red', ax=axes[1], label='True')\n",
    "sb.lineplot(x=range(len(temp_avg_pred)), y=temp_avg_pred, color='white', ax=axes[1], label='Pred')\n",
    "axes[1].set_title('average temperature')\n",
    "\n",
    "sb.lineplot(x=range(len(wind_true)), y=wind_true, color='red', ax=axes[2], label='True')\n",
    "sb.lineplot(x=range(len(wind_pred)), y=wind_pred, color='white', ax=axes[2], label='Pred')\n",
    "axes[2].set_title('wind speed')\n",
    "\n",
    "plt.suptitle('Predictions', fontweight='bold')\n",
    "plt.tight_layout()"
   ],
   "id": "f6f05d13a84962d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# III - Conclusion\n",
    "Clearly the model doesn't understand the chaos that is in the _precipitation_ and _wind_ columns. <br>\n",
    "I suppose predicting such thing as weather with both high precision <br>\n",
    "and large amount of features requires more than just 3 numeric columns. <br>\n",
    "Despite this fact the model did decent job with predicting average temperature and recognizing patterns inside. <br><br>\n",
    "Overall I think this project gives quiet simple fundamentals to understand the functionality of Recurrent Neural Networks.\n",
    "#### Thanks for reading my project, I hope you enjoyed the process :]\n",
    "_Gracjan Pawłowski 2025_"
   ],
   "id": "66e02b2ff3215bed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
