{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "In this small project we will take a look at Seattle weather dataset from Kaggle to extract important features and use them to test functionality of Recurrent Neural Network.\n",
    "<br><br>\n",
    "#### Main objective\n",
    "Build a model using PyTorch library that predict weather features such as average temperature, wind and precipitation.\n",
    "<br><br>\n",
    "#### Process includes:\n",
    "1. **Data** <br>\n",
    "&ensp;1.1 Overview <br>\n",
    "&ensp;1.2 Anomalies <br>\n",
    "&ensp;1.3 Visualization <br>\n",
    "&ensp;1.4 Preparing data for model <br>\n",
    "2. **Building model** <br>\n",
    "&ensp;2.1 Train / test split <br>\n",
    "&ensp;2.2 Sequencing datasets <br>\n",
    "&ensp;2.3 Class LSTM <br>\n",
    "&ensp;2.4 Training function <br>\n",
    "&ensp;2.5 Testing function <br>\n",
    "&ensp;2.6 Training and Testing the RNN models <br>\n",
    "3. **Conclusion**"
   ],
   "id": "9f988730a9f468c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# I - Data\n",
    "#### 1.1 Overview\n",
    "To preview dataset we're going to use pandas library"
   ],
   "id": "f6676f7817f4eef5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"DON'T MIND THIS, it's dark theme for matplotlib\"\"\"\n",
    "WHITE_MID = '#b5b5b5'\n",
    "GREY_DARK = '#141414'\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = GREY_DARK\n",
    "plt.rcParams['text.color'] = WHITE_MID\n",
    "plt.rcParams['axes.facecolor'] = GREY_DARK\n",
    "plt.rcParams['axes.edgecolor'] = WHITE_MID\n",
    "plt.rcParams['axes.labelcolor'] = WHITE_MID\n",
    "plt.rcParams['axes.titlecolor'] = WHITE_MID\n",
    "\n",
    "plt.rcParams['grid.color'] = WHITE_MID\n",
    "plt.rcParams['grid.linestyle'] = '--'\n",
    "plt.rcParams['grid.linewidth'] = 0.5\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "plt.rcParams['xtick.color'] = WHITE_MID\n",
    "plt.rcParams['ytick.color'] = WHITE_MID\n",
    "plt.rcParams['legend.edgecolor'] = WHITE_MID\n",
    "plt.rcParams['legend.labelcolor'] = WHITE_MID"
   ],
   "id": "f591f0f57656af6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('seattle-weather.csv')\n",
    "df"
   ],
   "id": "e8c4d9b7e5bfddd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Following authors description: <br><br>\n",
    "**_precipitation_** - all forms in which water falls on the land surface and open water bodies as rain, sleet, snow, hail, or drizzle <br>\n",
    "**_temp_max_** - highest temperature recorded that day <br>\n",
    "**_temp_min_** - lowest temperature recorded that day <br>\n",
    "**_wind_** - wind speed <br>\n",
    "**_weather_** - weather condition <br>"
   ],
   "id": "df9649ef72576e52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# convert date to actual date format and attach it to index column\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)"
   ],
   "id": "bbc1823844eadfd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.describe()",
   "id": "55398efe5d19e79e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.isna().sum()",
   "id": "474513e1d364249b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It is impossible to recreate the situation I described below in the real world, <br>\n",
    "but we are looking for this type of anomaly."
   ],
   "id": "c079434c9fccc322"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[df['temp_max'] < df['temp_min']]",
   "id": "63935ca438c221da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "\"rainy\" weather but no actual rain",
   "id": "ddd29be56213d442"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_rainy = df['weather'] == 'rain'\n",
    "df_noprecip = df['precipitation'] == 0\n",
    "df[(df_rainy) & (df_noprecip)]"
   ],
   "id": "61b829113ae20d07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It's sketchy, but I guess the weather 'rain' doesn't mean we have to expect rain that day but the 'feeling' of the weather.",
   "id": "1e644562451d97e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.groupby('weather').mean()",
   "id": "9940d8b027d411fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1.3 Visualization\n",
    "Using heatmaps, lineplots from seaborn to find correlations and patterns."
   ],
   "id": "80b7da83f012917"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "id": "e4342ca5512aa0fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr = df.drop(['weather'], axis=1).corr()\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "sb.heatmap(corr, annot=True, cmap='Greys_r', cbar=False, mask=np.triu(np.ones(len(corr)), k=0))\n",
    "plt.title('Correlation')"
   ],
   "id": "a64a489c6eb3cbd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(ncols=1, nrows=3, figsize=(24, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "mid_blue = '#6f93bf'\n",
    "mid_red = '#bf6f6f'\n",
    "\n",
    "sb.lineplot(data=df, x='date', y='temp_max', color=mid_red, ax=axes[0])\n",
    "sb.lineplot(data=df, x='date', y='temp_min', color=mid_blue, ax=axes[0])\n",
    "sb.lineplot(data=df, x='date', y='wind', color=mid_blue, ax=axes[1])\n",
    "sb.lineplot(data=df, x='date', y='precipitation', color=mid_blue, ax=axes[2])\n",
    "\n",
    "axes[0].set_title('Temperature min, max')\n",
    "axes[1].set_title('Wind speed')\n",
    "axes[2].set_title('Precipitation')\n",
    "\n",
    "fig.suptitle('Trends Over Time - Daily', fontweight='bold')\n",
    "plt.tight_layout()"
   ],
   "id": "223ad25308d61c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Seasonal pattern suggests that more precipitations appear in autumn months.<br>\n",
    "During summer season wind speed varies between maximum and minimum values notably more comparing to winter season.<br>"
   ],
   "id": "717a6f06945240da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Since both temp_min and temp_max change almost the same way, and we don't have timestamps of each hour per day. We can extract _**average temperature**_ that day. <br>\n",
    "This can reduce the number of values for the model to calculate and change the input size by removing redundant features."
   ],
   "id": "a2750b95c14bf5d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "temp_avg = (df['temp_max'] + df['temp_min']) / 2\n",
    "df.drop(['temp_max', 'temp_min'], axis=1, inplace=True)\n",
    "df.insert(1, 'temp_avg', temp_avg)\n",
    "df"
   ],
   "id": "2055e85a5d36e828",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I've created 3 time resampled versions of the same dataframe so the plot is easier to read.",
   "id": "2178f07710cf7c61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_daily = df.drop('weather', axis=1).resample('D').mean()\n",
    "df_weekly = df.drop('weather', axis=1).resample('W').mean()\n",
    "df_monthly = df.drop('weather', axis=1).resample('ME').mean()\n",
    "df_monthly.head()"
   ],
   "id": "c5b74119d83bb432",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(ncols=1, nrows=3, figsize=(24, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "sb.lineplot(data=df_weekly, x='date', y='temp_avg', color=mid_red, ax=axes[0])\n",
    "sb.lineplot(data=df_weekly, x='date', y='wind', color=mid_blue, ax=axes[1])\n",
    "sb.lineplot(data=df_weekly, x='date', y='precipitation', color=mid_blue, ax=axes[2])\n",
    "\n",
    "axes[0].set_title('Average Temperature')\n",
    "axes[1].set_title('Wind speed')\n",
    "axes[2].set_title('Precipitation')\n",
    "\n",
    "plt.suptitle('Trends Over Time - Weekly', fontweight='bold')\n",
    "plt.tight_layout()"
   ],
   "id": "2cc3ec702ca3f1c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "sb.countplot(data=df, x='weather', color=mid_blue, edgecolor='none')"
   ],
   "id": "4dd2f3f1a492793d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1.4 Preparing data for model\n",
    "First we have to convert our weather condition labels to actual numeric values, <br>\n",
    "because the RNN model classification expect labels with dtype of integer. <br>\n",
    "For this I'm going to use simple dictionaries."
   ],
   "id": "a33ca51412505089"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "weather_to_idx = {\n",
    "    k: v for v, k in enumerate(df['weather'].unique())\n",
    "}\n",
    "idx_to_weather = {\n",
    "    k: v for k, v in enumerate(df['weather'].unique())\n",
    "}\n",
    "weather_to_idx"
   ],
   "id": "680736e55f3253e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Just making sure if backwards conversion is fine.",
   "id": "24ee7afa85d8ee2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for w in df['weather'].unique():\n",
    "    print(f\"{w:>10}:\", w == idx_to_weather[weather_to_idx[w]])"
   ],
   "id": "e38e15b22fad621f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['weather'] = df['weather'].apply(lambda x: weather_to_idx[x])\n",
    "df"
   ],
   "id": "df310191dca4f948",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We're going to pass sequenced data with length of 7 days per sequence. <br>\n",
    "Knowing that, we have to make sure that our dataset is divisible by 7, <br>\n",
    "we can simply cut it to the exact length of full weeks it contains."
   ],
   "id": "fd64df1f598cc281"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_weeks = len(df) // 7 * 7\n",
    "df = df[:n_weeks]"
   ],
   "id": "4e117820c68ba79b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Normalizing features using _**MinMaxScaler**_.",
   "id": "72ad9644c01191eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "features = ['precipitation', 'temp_avg', 'wind']\n",
    "\n",
    "for feat in features:\n",
    "    print(\n",
    "        f'{feat}\\n',\n",
    "        f'min: {df[feat].min()}',\n",
    "        f'max: {df[feat].max()}',\n",
    "        end='\\n\\n'\n",
    "    )"
   ],
   "id": "9d1e859fa3a87a50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df.loc[:, features] = scaler.fit_transform(df[features])"
   ],
   "id": "9c6f3906d0498c57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "features = ['precipitation', 'temp_avg', 'wind']\n",
    "\n",
    "for feat in features:\n",
    "    print(\n",
    "        f'{feat}\\n',\n",
    "        f'min: {df[feat].min()}',\n",
    "        f'max: {df[feat].max()}',\n",
    "        end='\\n\\n'\n",
    "    )"
   ],
   "id": "e284aad97b56ee8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# II - Building model\n",
    "#### 2.1 Train / test split\n",
    "Splitting dataset using week stamps."
   ],
   "id": "d9e285270e10d81d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_weeks = int(len(df) / 7)\n",
    "n_weeks"
   ],
   "id": "58d7d5fb8e06ba9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_size = int(n_weeks * 0.7) + 1\n",
    "test_size = int(n_weeks * 0.3)\n",
    "\n",
    "print(\n",
    "    f\"{f\"train size\":>12}: {train_size}\",\n",
    "    f\"{f\"test size\":>12}: {test_size}\", sep='\\n'\n",
    ")"
   ],
   "id": "9b2debeeda67b756",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_train = df[: train_size*7]\n",
    "df_test = df[train_size*7 :]"
   ],
   "id": "7f687d508b204799",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\n",
    "    len(df_train) / 7,\n",
    "    len(df_test) / 7, sep='\\n'\n",
    ")"
   ],
   "id": "592dd950e6fb063d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First we convert each data split to numpy, so we're able to pass it to torch.",
   "id": "14c9b4a8b7765d10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "id": "d0b1545a5df10f7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_train_torch = df_train.to_numpy()\n",
    "df_train_torch = torch.tensor(df_train_torch)\n",
    "\n",
    "df_test_torch = df_test.to_numpy()\n",
    "df_test_torch = torch.tensor(df_test_torch)\n",
    "df_test_torch[:7]"
   ],
   "id": "f6de761f5c5ade6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.2 - Sequencing datasets\n",
    "To predict weather conditions based on features from past 6 days, <br>\n",
    "we have to reshape our data split sets to return specific sequences. <br><br>\n",
    "Each sequence containing data from 7 days, where: <br>\n",
    "X - precipitation, temp_avg and wind speed features from past 6 days <br>\n",
    "y - same features, but we take just day 7"
   ],
   "id": "e90715a5b5a46716"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def sequence_dataset(dataset, batch_size):\n",
    "    \n",
    "    x, y = [], []\n",
    "    \n",
    "    for i in range(0, len(dataset) - 7):\n",
    "        \n",
    "        week = dataset[i: i + 7, :3] # take everything except 'weather'\n",
    "        week_features = week[:6, :] # trim to 6 days\n",
    "        week_target = week[-1, :] # take last day\n",
    "        \n",
    "        x.append(week_features)\n",
    "        y.append(week_target)\n",
    "        \n",
    "    # covert to tensor dataset\n",
    "    tensor_dataset = TensorDataset(torch.tensor(np.asarray(x)),\n",
    "                                   torch.tensor(np.asarray(y)))\n",
    "    \n",
    "    # covert to data_loader\n",
    "    data_loader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    return data_loader"
   ],
   "id": "f55402288d2398b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 4\n",
    "train_loader = sequence_dataset(df_train_torch, batch_size=batch_size)\n",
    "test_loader = sequence_dataset(df_test_torch, batch_size=batch_size)"
   ],
   "id": "5d1936ec49fb6c44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "i = 2\n",
    "\n",
    "for batch in test_loader:\n",
    "    input, target = batch\n",
    "    print(input.size())\n",
    "    print(target.size())\n",
    "    break"
   ],
   "id": "772b0da72f919eee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The shape corresponds to: <br>\n",
    "&emsp;4 - batch size <br>\n",
    "&emsp;6 - n days in sequence <br>\n",
    "&emsp;3 - n features for single day <br><br>\n",
    "Note that before I've said that sequence is 7 days but our input is now 6 days. That's because the 7th day became y/label."
   ],
   "id": "33214b25584008c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for batch in train_loader:\n",
    "    input, target = batch\n",
    "    print(input[0], target[0], sep='\\n')\n",
    "    break"
   ],
   "id": "d2c519b521e703a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.3 class LSTM\n",
    "With PyTorch we are able to build simple RNN with Long Short-Term Memory layers by simply attaching _nn.LSTM()_ with specific factors in it. <br>\n",
    "The __init__ function first initializes the LSTM and fully connected layers. <br>\n",
    "__*forward()*__ passes our input x to the rnn network then fully connects it to finally return last value from the output."
   ],
   "id": "9736826d8b8f86f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "class WeatherRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=3, n_layers=2, dropout=0):\n",
    "        super(WeatherRNN, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :]) # take the last value\n",
    "        return out"
   ],
   "id": "a6d6ea3cef0ac0da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.4 Training function\n",
    "So we take our train_loader and pass it to our training function. <br>\n",
    "Training function iterates over batches for n_epoch times and passes sequences from these batches to our model <br>\n",
    "that calculates loss by comparing calculated outputs with actual targets using Mean Squared Error function."
   ],
   "id": "64ddf19a565f0f9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, device, train_loader, n_epochs=1, lr=0.001):\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = (inputs.to(device).float(),\n",
    "                               targets.to(device).float())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1} / {n_epochs} finished | {total_loss/len(train_loader):.4f}\")"
   ],
   "id": "c149884f8a3e3ac7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.5 Testing function\n",
    "Similar to training function. This time we run the model with no gradients calculations <br>\n",
    "and iterate through batches from test_loader. <br>\n",
    "Then return y true and y predicted values to compare where the model makes most mistakes."
   ],
   "id": "f2c8ce9e9d98917d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def test_model(model, device, test_loader):\n",
    "    total_loss = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = (inputs.to(device).float(),\n",
    "                               targets.to(device).float())\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            y_true.extend(targets.cpu().numpy())\n",
    "            y_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    print(f\"Test MSE Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return y_true, y_pred\n"
   ],
   "id": "e03eaec27e834ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.6 Training and Testing the RNN models",
   "id": "7981d93c47fcbaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_size = 3\n",
    "output_size = 3\n",
    "hidden_size = 32\n",
    "n_layers = 2\n",
    "dropout = 0.5\n",
    "learning_rate = 0.0001\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "weather_rnn = WeatherRNN(input_size=input_size, hidden_size=hidden_size, n_layers=n_layers, output_size=output_size, dropout=dropout)"
   ],
   "id": "4b78278af1d420aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_model(weather_rnn, device=device, train_loader=train_loader, n_epochs=n_epochs, lr=learning_rate)",
   "id": "408c9346150f64ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_true, y_pred = test_model(weather_rnn, device=device, test_loader=test_loader)",
   "id": "458a0553885943",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "precip_true = np.array(y_true)[:, 0]\n",
    "precip_pred = np.array(y_pred)[:, 0]\n",
    "\n",
    "temp_avg_true = np.array(y_true)[:, 1]\n",
    "temp_avg_pred = np.array(y_pred)[:, 1]\n",
    "\n",
    "wind_true = np.array(y_true)[:, 2]\n",
    "wind_pred = np.array(y_pred)[:, 2]"
   ],
   "id": "28f68446dac39720",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(30, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "sb.lineplot(x=range(len(precip_true)), y=precip_true, color='red', ax=axes[0], label='True')\n",
    "sb.lineplot(x=range(len(precip_pred)), y=precip_pred, color='white', ax=axes[0], label='Pred')\n",
    "axes[0].set_title('precipitation predictions')\n",
    "\n",
    "sb.lineplot(x=range(len(temp_avg_true)), y=temp_avg_true, color='red', ax=axes[1], label='True')\n",
    "sb.lineplot(x=range(len(temp_avg_pred)), y=temp_avg_pred, color='white', ax=axes[1], label='Pred')\n",
    "axes[1].set_title('temp_avg predictions')\n",
    "\n",
    "sb.lineplot(x=range(len(wind_true)), y=wind_true, color='red', ax=axes[2], label='True')\n",
    "sb.lineplot(x=range(len(wind_pred)), y=wind_pred, color='white', ax=axes[2], label='Pred')\n",
    "axes[2].set_title('wind predictions')"
   ],
   "id": "f6f05d13a84962d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# III - Conclusion\n",
    "Clearly the model doesn't understand the chaos that is in the _precipitation_ and _wind_ columns. <br>\n",
    "I suppose predicting such thing as weather with both high precision <br>\n",
    "and large amount of features requires more than just 3 numeric columns. <br>\n",
    "Despite this fact the model did decent job with predicting average temperature. <br><br>\n",
    "Overall I think this project gives quiet simple fundamentals to understand the functionality of Recurrent Neural Networks.\n",
    "#### Thanks for reading my project, I hope you enjoyed the process :]\n",
    "_Gracjan Paw≈Çowski 2025_"
   ],
   "id": "66e02b2ff3215bed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
